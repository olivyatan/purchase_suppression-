{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a18bc6e-247b-4c9d-a7d0-e54f610a566a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/08 07:58:51 INFO SecurityManager: Changing view acls to: olivyatan,b_perso,*\n",
      "24/10/08 07:58:51 INFO SecurityManager: Changing modify acls to: olivyatan,b_perso\n",
      "24/10/08 07:58:51 INFO SecurityManager: Changing view acls groups to: \n",
      "24/10/08 07:58:51 INFO SecurityManager: Changing modify acls groups to: \n",
      "24/10/08 07:58:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(olivyatan, b_perso, *); groups with view permissions: Set(); users  with modify permissions: Set(olivyatan, b_perso); groups with modify permissions: Set()\n",
      "24/10/08 07:58:51 INFO deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "24/10/08 07:58:52 INFO SparkContext: Running Spark version 3.1.1.0.1.0\n",
      "24/10/08 07:58:52 INFO ResourceUtils: ==============================================================\n",
      "24/10/08 07:58:52 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "24/10/08 07:58:52 INFO ResourceUtils: ==============================================================\n",
      "24/10/08 07:58:52 INFO SparkContext: Submitted application: purchase-suppression-tmp\n",
      "24/10/08 07:58:52 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memoryOverhead -> name: memoryOverhead, amount: 4096, script: , vendor: , cores -> name: cores, amount: 3, script: , vendor: , memory -> name: memory, amount: 20480, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "24/10/08 07:58:52 INFO ResourceProfile: Limiting resource is cpus at 3 tasks per executor\n",
      "24/10/08 07:58:52 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "24/10/08 07:58:52 INFO SecurityManager: Changing view acls to: olivyatan,b_perso,*\n",
      "24/10/08 07:58:52 INFO SecurityManager: Changing modify acls to: olivyatan,b_perso\n",
      "24/10/08 07:58:52 INFO SecurityManager: Changing view acls groups to: \n",
      "24/10/08 07:58:52 INFO SecurityManager: Changing modify acls groups to: \n",
      "24/10/08 07:58:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(olivyatan, b_perso, *); groups with view permissions: Set(); users  with modify permissions: Set(olivyatan, b_perso); groups with modify permissions: Set()\n",
      "24/10/08 07:58:52 INFO Utils: Successfully started service 'sparkDriver' on port 30202.\n",
      "24/10/08 07:58:52 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/10/08 07:58:52 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/10/08 07:58:52 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "24/10/08 07:58:52 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "24/10/08 07:58:52 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/10/08 07:58:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5c485a39-0a52-4ff6-bca1-b147cdf35097\n",
      "24/10/08 07:58:52 INFO MemoryStore: MemoryStore started with capacity 10.5 GiB\n",
      "24/10/08 07:58:52 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "24/10/08 07:58:53 INFO log: Logging initialized @4455ms to org.sparkproject.jetty.util.log.Slf4jLog\n",
      "24/10/08 07:58:53 INFO Server: jetty-9.4.36.v20210114; built: 2021-01-14T16:44:28.689Z; git: 238ec6997c7806b055319a6d11f8ae7564adc0de; jvm 1.8.0_292-b10\n",
      "24/10/08 07:58:53 INFO Server: Started @4565ms\n",
      "24/10/08 07:58:53 INFO AbstractConnector: Started ServerConnector@1c363dd4{HTTP/1.1, (http/1.1)}{0.0.0.0:30401}\n",
      "24/10/08 07:58:53 INFO Utils: Successfully started service 'SparkUI' on port 30401.\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6cc3e03a{/jobs,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@189612ee{/jobs/json,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6572ea4f{/jobs/job,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6eac872c{/jobs/job/json,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3dab4ac{/stages,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@75796f72{/stages/json,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4e82fe8c{/stages/stage,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@24f4666f{/stages/stage/json,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7d7c03ff{/stages/pool,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5bc82ac7{/stages/pool/json,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4b6cdfb0{/storage,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4a3ad968{/storage/json,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@23bb0b0b{/storage/rdd,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1d373b03{/storage/rdd/json,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@56394f99{/environment,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@21654689{/environment/json,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1feca07a{/executors,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@65b9e52a{/executors/json,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@372138c1{/executors/threadDump,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6eb0f465{/executors/threadDump/json,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3846bfaa{/static,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@711ddb9c{/,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@40be2dfb{/api,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1779da{/jobs/job/kill,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@56e21017{/stages/stage/kill,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:58:53 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.198.253.55:30401\n",
      "24/10/08 07:58:53 INFO SparkContext: Added file /data/shpx/notebooks/hroitman/Purchase-Suppression/feature_helpers.py at spark://10.198.253.55:30202/files/feature_helpers.py with timestamp 1728374332066\n",
      "24/10/08 07:58:53 INFO Utils: Copying /data/shpx/notebooks/hroitman/Purchase-Suppression/feature_helpers.py to /tmp/spark-99bd57ab-f09d-4dab-b4cd-73490e8afa48/userFiles-99afc123-e72b-460f-b66a-24c811803656/feature_helpers.py\n",
      "24/10/08 07:58:53 INFO HadoopDelegationTokenManager: Attempting to load user's ticket cache.\n",
      "24/10/08 07:58:53 INFO HadoopFSDelegationTokenProvider: getting token for: org.apache.hadoop.fs.viewfs.ViewFileSystem@56df0157 with renewer rm/apollo-rno-rm-1.vip.hadoop.ebay.com@PROD.EBAY.COM\n",
      "24/10/08 07:58:54 INFO DFSClient: Created token for b_perso: HDFS_DELEGATION_TOKEN owner=b_perso@PROD.EBAY.COM, renewer=yarn, realUser=, issueDate=1728374334538, maxDate=1728979134538, sequenceNumber=240713470, masterKeyId=34528 on ha-hdfs:apollo-router\n",
      "24/10/08 07:58:54 INFO HadoopFSDelegationTokenProvider: getting token for: org.apache.hadoop.fs.viewfs.ViewFileSystem@56df0157 with renewer b_perso@PROD.EBAY.COM\n",
      "24/10/08 07:58:54 INFO DFSClient: Created token for b_perso: HDFS_DELEGATION_TOKEN owner=b_perso@PROD.EBAY.COM, renewer=b_perso, realUser=, issueDate=1728374334583, maxDate=1728979134583, sequenceNumber=240713471, masterKeyId=34528 on ha-hdfs:apollo-router\n",
      "24/10/08 07:58:54 INFO HadoopFSDelegationTokenProvider: Renewal interval is 86400057 for token HDFS_DELEGATION_TOKEN\n",
      "24/10/08 07:58:55 INFO HiveConf: Found configuration file file:/apache/releases/apache-hive-1.2.1000.2.6.4.2.0.23-bin/conf/hive-site.xml\n",
      "24/10/08 07:58:56 WARN HiveConf: DEPRECATED: hive.metastore.ds.retry.* no longer has any effect.  Use hive.hmshandler.retry.* instead\n",
      "24/10/08 07:58:56 WARN HiveConf: HiveConf of name hive.metastore.local does not exist\n",
      "24/10/08 07:58:56 WARN HiveConf: HiveConf of name hive.enforce.sorting does not exist\n",
      "24/10/08 07:58:56 WARN HiveConf: HiveConf of name hive.server2.proxyuser.hue.groups does not exist\n",
      "24/10/08 07:58:56 WARN HiveConf: HiveConf of name hive.server2.proxyuser.hue.hosts does not exist\n",
      "24/10/08 07:58:56 WARN HiveConf: HiveConf of name hive.metastore.ds.retry.interval does not exist\n",
      "24/10/08 07:58:56 WARN HiveConf: HiveConf of name hive.enforce.bucketing does not exist\n",
      "24/10/08 07:58:56 WARN HiveConf: HiveConf of name hive.metastore.ds.retry.attempts does not exist\n",
      "24/10/08 07:58:56 WARN HiveConf: HiveConf of name hive.server2.enable.impersonation does not exist\n",
      "24/10/08 07:58:56 INFO deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "24/10/08 07:58:56 INFO SparkHadoopUtil: Updating delegation tokens for current user.\n",
      "24/10/08 07:58:56 INFO Utils: Using initial executors = 10, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances\n",
      "24/10/08 07:58:57 INFO RemoteConfig: Merged with remote configs\n",
      "24/10/08 07:58:57 INFO Client: Requesting a new application from cluster with 12878 NodeManagers\n",
      "24/10/08 07:58:57 INFO Configuration: resource-types.xml not found\n",
      "24/10/08 07:58:57 INFO ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "24/10/08 07:58:57 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (65536 MB per container)\n",
      "24/10/08 07:58:57 INFO Client: Will allocate AM container, with 4505 MB memory including 409 MB overhead\n",
      "24/10/08 07:58:57 INFO Client: Setting up container launch context for our AM\n",
      "24/10/08 07:58:57 INFO Client: Setting up the launch environment for our AM container\n",
      "24/10/08 07:58:57 INFO Client: Preparing resources for our AM container\n",
      "24/10/08 07:58:57 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "24/10/08 07:58:58 INFO Client: Uploading resource file:/tmp/spark-99bd57ab-f09d-4dab-b4cd-73490e8afa48/__spark_libs__1316450296615364698.zip -> viewfs://apollo-rno/user/b_perso/.sparkStaging/application_1728324362732_160788/__spark_libs__1316450296615364698.zip\n",
      "24/10/08 07:59:00 INFO Client: Uploading resource file:/data/shpx/notebooks/hroitman/Purchase-Suppression/feature_helpers.py -> viewfs://apollo-rno/user/b_perso/.sparkStaging/application_1728324362732_160788/feature_helpers.py\n",
      "24/10/08 07:59:00 INFO Client: Uploading resource file:/data/shpx/data/mpalei/spark-3.1.1.0.1.0-bin-ebay/python/lib/pyspark.zip -> viewfs://apollo-rno/user/b_perso/.sparkStaging/application_1728324362732_160788/pyspark.zip\n",
      "24/10/08 07:59:00 INFO Client: Uploading resource file:/data/shpx/data/mpalei/spark-3.1.1.0.1.0-bin-ebay/python/lib/py4j-0.10.9-src.zip -> viewfs://apollo-rno/user/b_perso/.sparkStaging/application_1728324362732_160788/py4j-0.10.9-src.zip\n",
      "24/10/08 07:59:00 INFO Client: Uploading resource file:/tmp/spark-99bd57ab-f09d-4dab-b4cd-73490e8afa48/__spark_conf__5829085370666153998.zip -> viewfs://apollo-rno/user/b_perso/.sparkStaging/application_1728324362732_160788/__spark_conf__.zip\n",
      "24/10/08 07:59:00 INFO SecurityManager: Changing view acls to: olivyatan,b_perso,*\n",
      "24/10/08 07:59:00 INFO SecurityManager: Changing modify acls to: olivyatan,b_perso\n",
      "24/10/08 07:59:00 INFO SecurityManager: Changing view acls groups to: \n",
      "24/10/08 07:59:00 INFO SecurityManager: Changing modify acls groups to: \n",
      "24/10/08 07:59:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(olivyatan, b_perso, *); groups with view permissions: Set(); users  with modify permissions: Set(olivyatan, b_perso); groups with modify permissions: Set()\n",
      "24/10/08 07:59:01 INFO Client: Submitting application application_1728324362732_160788 to ResourceManager\n",
      "24/10/08 07:59:02 INFO YarnClientImpl: Application submission is not finished, submitted application application_1728324362732_160788 is still in SUBMITTED\n",
      "24/10/08 07:59:04 INFO YarnClientImpl: Application submission is not finished, submitted application application_1728324362732_160788 is still in SUBMITTED\n",
      "24/10/08 07:59:07 INFO YarnClientImpl: Application submission is not finished, submitted application application_1728324362732_160788 is still in SUBMITTED\n",
      "24/10/08 07:59:09 INFO YarnClientImpl: Application submission is not finished, submitted application application_1728324362732_160788 is still in SUBMITTED\n",
      "24/10/08 07:59:10 INFO YarnClientImpl: Submitted application application_1728324362732_160788\n",
      "24/10/08 07:59:11 INFO Client: Application report for application_1728324362732_160788 (state: ACCEPTED)\n",
      "24/10/08 07:59:11 INFO Client: \n",
      "\t client token: N/A\n",
      "\t diagnostics: N/A\n",
      "\t ApplicationMaster host: N/A\n",
      "\t ApplicationMaster RPC port: -1\n",
      "\t queue: hddq-exprce-perso-high-mem\n",
      "\t start time: 1728374341062\n",
      "\t final status: UNDEFINED\n",
      "\t tracking URL: https://apollo-rno-rm-1.vip.hadoop.ebay.com:50030/proxy/application_1728324362732_160788/\n",
      "\t user: b_perso\n",
      "24/10/08 07:59:12 INFO Client: Application report for application_1728324362732_160788 (state: ACCEPTED)\n",
      "24/10/08 07:59:13 INFO Client: Application report for application_1728324362732_160788 (state: ACCEPTED)\n",
      "24/10/08 07:59:14 INFO Client: Application report for application_1728324362732_160788 (state: ACCEPTED)\n",
      "24/10/08 07:59:15 INFO Client: Application report for application_1728324362732_160788 (state: ACCEPTED)\n",
      "24/10/08 07:59:16 INFO Client: Application report for application_1728324362732_160788 (state: ACCEPTED)\n",
      "24/10/08 07:59:17 INFO Client: Application report for application_1728324362732_160788 (state: ACCEPTED)\n",
      "24/10/08 07:59:18 INFO Client: Application report for application_1728324362732_160788 (state: ACCEPTED)\n",
      "24/10/08 07:59:19 INFO Client: Application report for application_1728324362732_160788 (state: ACCEPTED)\n",
      "24/10/08 07:59:20 INFO Client: Application report for application_1728324362732_160788 (state: ACCEPTED)\n",
      "24/10/08 07:59:21 INFO Client: Application report for application_1728324362732_160788 (state: ACCEPTED)\n",
      "24/10/08 07:59:22 INFO Client: Application report for application_1728324362732_160788 (state: ACCEPTED)\n",
      "24/10/08 07:59:23 INFO Client: Application report for application_1728324362732_160788 (state: ACCEPTED)\n",
      "24/10/08 07:59:24 INFO Client: Application report for application_1728324362732_160788 (state: ACCEPTED)\n",
      "24/10/08 07:59:25 INFO Client: Application report for application_1728324362732_160788 (state: ACCEPTED)\n",
      "24/10/08 07:59:26 INFO Client: Application report for application_1728324362732_160788 (state: ACCEPTED)\n",
      "24/10/08 07:59:27 INFO Client: Application report for application_1728324362732_160788 (state: ACCEPTED)\n",
      "24/10/08 07:59:27 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> apollo-rno-rm-1.vip.hadoop.ebay.com,apollo-rno-rm-2.vip.hadoop.ebay.com, PROXY_URI_BASES -> https://apollo-rno-rm-1.vip.hadoop.ebay.com:50030/proxy/application_1728324362732_160788,https://apollo-rno-rm-2.vip.hadoop.ebay.com:50030/proxy/application_1728324362732_160788, RM_HA_URLS -> apollo-rno-rm-1.vip.hadoop.ebay.com:50030,apollo-rno-rm-2.vip.hadoop.ebay.com:50030), /proxy/application_1728324362732_160788\n",
      "24/10/08 07:59:28 INFO Client: Application report for application_1728324362732_160788 (state: RUNNING)\n",
      "24/10/08 07:59:28 INFO Client: \n",
      "\t client token: Token { kind: YARN_CLIENT_TOKEN, service:  }\n",
      "\t diagnostics: N/A\n",
      "\t ApplicationMaster host: 10.18.78.61\n",
      "\t ApplicationMaster RPC port: -1\n",
      "\t queue: hddq-exprce-perso-high-mem\n",
      "\t start time: 1728374341062\n",
      "\t final status: UNDEFINED\n",
      "\t tracking URL: https://apollo-rno-rm-1.vip.hadoop.ebay.com:50030/proxy/application_1728324362732_160788/\n",
      "\t user: b_perso\n",
      "24/10/08 07:59:28 INFO YarnClientSchedulerBackend: Application application_1728324362732_160788 has started running.\n",
      "24/10/08 07:59:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 30601.\n",
      "24/10/08 07:59:28 INFO NettyBlockTransferService: Server created on 10.198.253.55:30601\n",
      "24/10/08 07:59:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "24/10/08 07:59:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.198.253.55, 30601, None)\n",
      "24/10/08 07:59:28 INFO BlockManagerMasterEndpoint: Registering block manager 10.198.253.55:30601 with 10.5 GiB RAM, BlockManagerId(driver, 10.198.253.55, 30601, None)\n",
      "24/10/08 07:59:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.198.253.55, 30601, None)\n",
      "24/10/08 07:59:28 INFO BlockManager: external shuffle service port = 7337\n",
      "24/10/08 07:59:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.198.253.55, 30601, None)\n",
      "24/10/08 07:59:28 INFO ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\n",
      "24/10/08 07:59:28 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@2536b168{/metrics/json,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:59:28 INFO SingleEventLogFileWriter: Logging events to hdfs://apollo-rno/spark-logs/application_1728324362732_160788.lz4.inprogress\n",
      "24/10/08 07:59:28 INFO Utils: Using initial executors = 10, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances\n",
      "24/10/08 07:59:28 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!\n",
      "24/10/08 07:59:28 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)\n",
      "24/10/08 07:59:28 INFO SharedState: Setting hive.metastore.warehouse.dir ('/user/hive/warehouse') to the value of spark.sql.warehouse.dir ('/user/hive/warehouse').\n",
      "24/10/08 07:59:28 INFO SharedState: Warehouse path is '/user/hive/warehouse'.\n",
      "24/10/08 07:59:28 INFO ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\n",
      "24/10/08 07:59:28 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5f59a471{/SQL,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:59:28 INFO ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\n",
      "24/10/08 07:59:28 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@303f6c84{/SQL/json,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:59:28 INFO ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\n",
      "24/10/08 07:59:28 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@33fce1bf{/SQL/execution,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:59:28 INFO ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\n",
      "24/10/08 07:59:28 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@562233f{/SQL/execution/json,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:59:28 INFO ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\n",
      "24/10/08 07:59:28 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@41ffa337{/static/sql,null,AVAILABLE,@Spark}\n",
      "24/10/08 07:59:28 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\n"
     ]
    }
   ],
   "source": [
    "from utils import spark_session, save_table\n",
    "\n",
    "session = spark_session(\"purchase-suppression-tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d64439c-2576-4856-9112-4139ace876a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import features as F\n",
    "\n",
    "df_smp = session.table(\"bx_ps_samples_enriched_1\")\n",
    "df_prch = session.table(\"bx_ps_user_prch_hist_1\")\n",
    "df_vi = session.table(\"bx_ps_user_vi_hist_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e2d0c6b-6387-4fae-8ae2-eb0f5427a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_srch = session.table(\"bx_ps_user_srch_hist_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613efb66-04db-4529-a9f6-6bcf3f7e670a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# time_since_last_action_from_cat_in_days\n",
    "df_ft = F.f_time_since_last_action_from_cat_in_days(df_smp, df_prch, cat_type=\"LEAF\", action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_smp, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_time_since_last_action_from_cat_in_days(df_smp, df_prch, cat_type=\"LVL2\", action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_time_since_last_action_from_cat_in_days(df_smp, df_prch, cat_type=\"META\", action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_time_since_last_action_from_cat_in_days(df_smp, df_vi, cat_type=\"LEAF\", action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_time_since_last_action_from_cat_in_days(df_smp, df_vi, cat_type=\"LVL2\", action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_time_since_last_action_from_cat_in_days(df_smp, df_vi, cat_type=\"META\", action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "\n",
    "#num_actions_from_cat_in_last_x_days\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LEAF\", days=1, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LEAF\", days=2, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LEAF\", days=5, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LEAF\", days=7, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LEAF\", days=14, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LEAF\", days=30, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LEAF\", days=60, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LEAF\", days=90, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LEAF\", days=180, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LEAF\", days=360, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LVL2\", days=1, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LVL2\", days=2, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LVL2\", days=5, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LVL2\", days=7, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LVL2\", days=14, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LVL2\", days=30, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LVL2\", days=60, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LVL2\", days=90, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LVL2\", days=180, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"LVL2\", days=360, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"META\", days=1, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"META\", days=2, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"META\", days=5, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"META\", days=7, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"META\", days=14, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"META\", days=30, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"META\", days=60, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"META\", days=90, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"META\", days=180, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_prch, cat_type=\"META\", days=360, action_type=\"purchase\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LEAF\", days=1, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LEAF\", days=2, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LEAF\", days=5, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LEAF\", days=7, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LEAF\", days=14, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LEAF\", days=30, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LEAF\", days=60, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LEAF\", days=90, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LEAF\", days=180, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LEAF\", days=360, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LVL2\", days=1, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LVL2\", days=2, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LVL2\", days=5, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LVL2\", days=7, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LVL2\", days=14, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LVL2\", days=30, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LVL2\", days=60, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LVL2\", days=90, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LVL2\", days=180, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"LVL2\", days=360, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"META\", days=1, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"META\", days=2, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"META\", days=5, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"META\", days=7, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"META\", days=14, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"META\", days=30, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"META\", days=60, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"META\", days=90, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"META\", days=180, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_vi, cat_type=\"META\", days=360, action_type=\"view\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cca7634-a4cd-4d2c-a581-09e2e0a961a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cat_propensity_sim\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"LEAF\", days=7)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"LEAF\", days=14)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"LEAF\", days=30)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"LEAF\", days=60)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"LEAF\", days=90)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"LEAF\", days=180)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"LEAF\", days=360)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"LVL2\", days=7)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"LVL2\", days=14)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"LVL2\", days=30)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"LVL2\", days=60)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"LVL2\", days=90)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"LVL2\", days=180)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"LVL2\", days=360)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"META\", days=7)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"META\", days=14)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"META\", days=30)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"META\", days=60)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"META\", days=90)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"META\", days=180)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_prch, action_type=\"purchase\", cat_type=\"META\", days=360)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"LEAF\", days=7)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"LEAF\", days=14)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"LEAF\", days=30)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"LEAF\", days=60)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"LEAF\", days=90)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"LEAF\", days=180)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"LEAF\", days=360)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"LVL2\", days=7)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"LVL2\", days=14)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"LVL2\", days=30)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"LVL2\", days=60)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"LVL2\", days=90)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"LVL2\", days=180)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"LVL2\", days=360)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"META\", days=7)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"META\", days=14)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"META\", days=30)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"META\", days=60)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"META\", days=90)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"META\", days=180)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_vi, action_type=\"view\", cat_type=\"META\", days=360)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a556cd-7a87-4a3f-9719-9ccb2a64766a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#title_propensity_sim\n",
    "# df_ft = F.f_title_propensity_sim(df_smp, df_prch, action_type=\"purchase\", days=7)\n",
    "# df_res = F.add_feature(df_res, df_ft, join_key=\"ITEM_ID\", how=\"left\")\n",
    "\n",
    "# df_ft = F.f_title_propensity_sim(df_smp, df_prch, action_type=\"purchase\", days=14)\n",
    "# df_res = F.add_feature(df_res, df_ft, join_key=\"ITEM_ID\", how=\"left\")\n",
    "\n",
    "# df_ft = F.f_title_propensity_sim(df_smp, df_prch, action_type=\"purchase\", days=30)\n",
    "# df_res = F.add_feature(df_res, df_ft, join_key=\"ITEM_ID\", how=\"left\")\n",
    "\n",
    "# df_ft = F.f_title_propensity_sim(df_smp, df_prch, action_type=\"purchase\", days=60)\n",
    "# df_res = F.add_feature(df_res, df_ft, join_key=\"ITEM_ID\", how=\"left\")\n",
    "\n",
    "# df_ft = F.f_title_propensity_sim(df_smp, df_prch, action_type=\"purchase\", days=90)\n",
    "# df_res = F.add_feature(df_res, df_ft, join_key=\"ITEM_ID\", how=\"left\")\n",
    "\n",
    "# df_ft = F.f_title_propensity_sim(df_smp, df_prch, action_type=\"purchase\", days=180)\n",
    "# df_res = F.add_feature(df_res, df_ft, join_key=\"ITEM_ID\", how=\"left\")\n",
    "\n",
    "# df_ft = F.f_title_propensity_sim(df_smp, df_prch, action_type=\"purchase\", days=360)\n",
    "# df_res = F.add_feature(df_res, df_ft, join_key=\"ITEM_ID\", how=\"left\")\n",
    "\n",
    "# df_ft = F.f_title_propensity_sim(df_smp, df_vi, action_type=\"view\", days=7)\n",
    "# df_res = F.add_feature(df_res, df_ft, join_key=\"ITEM_ID\", how=\"left\")\n",
    "\n",
    "# df_ft = F.f_title_propensity_sim(df_smp, df_vi, action_type=\"view\", days=14)\n",
    "# df_res = F.add_feature(df_res, df_ft, join_key=\"ITEM_ID\", how=\"left\")\n",
    "\n",
    "# df_ft = F.f_title_propensity_sim(df_smp, df_vi, action_type=\"view\", days=30)\n",
    "# df_res = F.add_feature(df_res, df_ft, join_key=\"ITEM_ID\", how=\"left\")\n",
    "\n",
    "# df_ft = F.f_title_propensity_sim(df_smp, df_vi, action_type=\"view\", days=60)\n",
    "# df_res = F.add_feature(df_res, df_ft, join_key=\"ITEM_ID\", how=\"left\")\n",
    "\n",
    "# df_ft = F.f_title_propensity_sim(df_smp, df_vi, action_type=\"view\", days=90)\n",
    "# df_res = F.add_feature(df_res, df_ft, join_key=\"ITEM_ID\", how=\"left\")\n",
    "\n",
    "# df_ft = F.f_title_propensity_sim(df_smp, df_vi, action_type=\"view\", days=180)\n",
    "# df_res = F.add_feature(df_res, df_ft, join_key=\"ITEM_ID\", how=\"left\")\n",
    "\n",
    "# df_ft = F.f_title_propensity_sim(df_smp, df_vi, action_type=\"view\", days=360)\n",
    "# df_res = F.add_feature(df_res, df_ft, join_key=\"ITEM_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "810cc1b6-6757-427f-bd56-e070d12bceae",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                001]]]]]]\r"
     ]
    }
   ],
   "source": [
    "#save_table(session, df_res, \"bx_ps_features_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c81497-d64f-4d23-8807-61f40ee07ffa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# create a smaller version only with key, features and label\n",
    "df = session.table(\"bx_ps_features_1\")\n",
    "f_columns = [col for col in df.columns if col.startswith('f_')]\n",
    "f_columns.extend([\"BUYER_ID\", \"LEAF_CATEG_ID\", \"EVENT_TIMESTAMP\", \"label\", \"num_repurchases\"])\n",
    "df = df.select(f_columns)\n",
    "\n",
    "# split data to train/validation/test sets\n",
    "train, validation, test = df.randomSplit([0.7, 0.1, 0.2])\n",
    "\n",
    "# save\n",
    "save_table(session, train, \"bx_ps_features_train_1\")\n",
    "save_table(session, validation, \"bx_ps_features_valid_1\")\n",
    "save_table(session, test, \"bx_ps_features_test_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089330dc-1a0d-445f-8195-804a1b9ec67a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if session:\n",
    "    session.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b74cf-7020-46c3-bd27-8c582593a8da",
   "metadata": {},
   "source": [
    "### Add features of searches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b76c94a8-ad0e-44d6-9988-86df4746fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res=session.table( \"bx_ps_features_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "205db457-a18e-4018-8392-10ee706408d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 99999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check the number of columns\n",
    "num_columns = len(df_res.columns)\n",
    "print(f\"Number of columns: {num_columns}\")\n",
    "\n",
    "# Check the number of rows\n",
    "num_rows = df_res.count()\n",
    "print(f\"Number of rows: {num_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "687370b0-685c-4505-9890-679876ab9fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"LEAF\", days=7)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"LEAF\", days=14)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"LEAF\", days=30)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"LEAF\", days=60)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"LEAF\", days=90)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"LEAF\", days=180)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"LEAF\", days=360)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"LVL2\", days=7)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"LVL2\", days=14)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"LVL2\", days=30)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"LVL2\", days=60)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"LVL2\", days=90)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"LVL2\", days=180)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"LVL2\", days=360)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"META\", days=7)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"META\", days=14)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"META\", days=30)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"META\", days=60)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"META\", days=90)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"META\", days=180)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n",
    "\n",
    "df_ft = F.f_cat_propensity_sim(df_smp, df_srch, action_type=\"search\", cat_type=\"META\", days=360)\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1be0a022-3a00-4e1c-8cdf-ebda9381cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_since_last_action_from_cat_in_days\n",
    "df_ft = F.f_time_since_last_action_from_cat_in_days(df_smp, df_srch, cat_type=\"LEAF\", action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_time_since_last_action_from_cat_in_days(df_smp, df_srch, cat_type=\"LVL2\", action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_time_since_last_action_from_cat_in_days(df_smp, df_srch, cat_type=\"META\", action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92b65e72-4a13-4e35-86b6-e494b9a10007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_actions_from_cat_in_last_x_days\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LEAF\", days=1, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LEAF\", days=2, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LEAF\", days=5, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LEAF\", days=7, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LEAF\", days=14, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LEAF\", days=30, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LEAF\", days=60, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LEAF\", days=90, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LEAF\", days=180, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LEAF\", days=360, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"LEAF_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LVL2\", days=1, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LVL2\", days=2, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LVL2\", days=5, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LVL2\", days=7, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LVL2\", days=14, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LVL2\", days=30, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LVL2\", days=60, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LVL2\", days=90, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LVL2\", days=180, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"LVL2\", days=360, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"CATEG_LVL2_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"META\", days=1, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"META\", days=2, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"META\", days=5, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"META\", days=7, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"META\", days=14, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"META\", days=30, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"META\", days=60, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"META\", days=90, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"META\", days=180, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n",
    "\n",
    "df_ft = F.f_num_actions_from_cat_in_last_x_days(df_smp, df_srch, cat_type=\"META\", days=360, action_type=\"search\")\n",
    "df_res = F.add_feature(df_res, df_ft, join_key=\"META_CATEG_ID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f601c99-a5d6-4bf3-aabe-a97577e8b0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 93:==================================================> (972 + 28) / 1000]]]]]]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 99999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check the number of columns\n",
    "num_columns = len(df_res.columns)\n",
    "print(f\"Number of columns: {num_columns}\")\n",
    "\n",
    "# Check the number of rows\n",
    "num_rows = df_res.count()\n",
    "print(f\"Number of rows: {num_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ca75310-d8e9-4e1b-a357-f3a03908f75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                00]]]]]]]\r"
     ]
    }
   ],
   "source": [
    "save_table(session, df_res, \"bx_ps_features_srch_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bde19e2d-12e3-450e-be61-fb29404ac332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# create a smaller version only with key, features and label #(\"bx_ps_features_1\") \n",
    "df = session.table(\"bx_ps_features_srch_1\")\n",
    "f_columns = [col for col in df.columns if col.startswith('f_')]\n",
    "f_columns.extend([\"BUYER_ID\", \"LEAF_CATEG_ID\", \"EVENT_TIMESTAMP\", \"label\", \"num_repurchases\"])\n",
    "df = df.select(f_columns)\n",
    "\n",
    "# split data to train/validation/test sets\n",
    "train, validation, test = df.randomSplit([0.7, 0.1, 0.2])\n",
    "\n",
    "# save # prev bx_ps_features_train_1 , bx_ps_features_valid_1, bx_ps_features_test_1 \n",
    "save_table(session, train, \"bx_ps_features_train_srch_1\")\n",
    "save_table(session, validation, \"bx_ps_features_valid_srch_1\")\n",
    "save_table(session, test, \"bx_ps_features_test_srch_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a14c0-9d4f-4516-b11f-cbb8ed11ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "if session:\n",
    "    session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
